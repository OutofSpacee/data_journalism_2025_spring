---
title: "lab_11"
author: "Derek Willis"
date: "2025-01-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## You will need

-   Our usual libraries for working with data, plus rvest and lubridate.

## Load libraries and establish settings

**Task** Create a codeblock and load appropriate packages and settings for this lab.

```{r}

library(rvest)
library(tidyverse)
library(janitor)
library(lubridate)
library(tidytext)

```


Let's get to scraping.

## Questions

**Q1**. Scrape the listing of available Maryland physician disciplinary alerts at <https://www.mbp.state.md.us/disciplinary_2024.aspx> into a dataframe. You should have three columns, one of which is a date, so make sure the date column has a date datatype. What's the most common sanction, and how many times is it mentioned in the 2024 alerts?

**Summary Suspension Affirmed and it is mentioned 7 times along with Surrender of License. ** 

```{r URL}

phy_dis_url <- "https://www.mbp.state.md.us/disciplinary_2024.aspx"

```

```{r Getting}

md_phy_data <- phy_dis_url |>
  read_html() |>
  html_table()

md_phy_data <- md_phy_data[[1]]

md_phy_data

```


```{r Cleaning}

cleaned_md_phy_data <- md_phy_data |>
  clean_names() |>
  mutate(clean_date = mdy(date))

cleaned_md_phy_data

```

```{r Most common sanction}

cleaned_md_phy_data |>
  group_by(sanction) |>
  summarise(
    count = n()
  ) |>
  arrange(desc(count))

```


**Q2** Next, let's scrape the list of press releases from Maryland's Office of the Public Defender, <https://www.opd.state.md.us/press-releases>. This isn't a table, so you'll need to use `html_elements()` and your browser's inspector and do some clean up on the results. The result should be a dataframe with two columns that contain the date and title, and the date column should have a date datatype. The challenge here is figuring out how to isolate the releases.

When you finish scraping into a dataframe, write code to find the press releases that have the word "police" in the title.

**There are 9 releases with the word "police" in the release title.** 

```{r}

press_re_url <- "https://www.opd.state.md.us/press-releases"

```

```{r Getting}

press_re_data <- press_re_url |>
  read_html() |>
  html_elements('p.wixui-rich-text__text span a') |>
  html_text() |>
  as_tibble()

press_re_data

```


```{r Cleaning}

cleaned_press_re_data <- press_re_data |>
  mutate(
    c_value = str_squish(value)
  ) |>
  separate(c_value, c('date', 'title'), sep=":") |>
  mutate(release_title = str_squish(title)) |>
  mutate(clean_date = mdy(date))

cleaned_press_re_data

```

```{r Finding Police}

cleaned_press_re_data |>
  filter(str_detect(str_to_lower(release_title), "police"))

```


**Q3** Sen. Chris Van Hollen, D-Maryland, has posted press releases at <https://www.vanhollen.senate.gov/news/press-releases>. It would be great to have them in a dataframe that has the following columns: date, title and url.

To do this, you will need to scrape the page's html and save that to a variable, and *then* extract the dates, titles and urls into separate dataframes using html_elements(). There are two different elements that contain the press release URL; pick one of them, and you may need to invoke an HTML `class` value to do it. The function `html_text()` pulls out the contents of a tag, but for urls we want the HTML attribute. Rvest gives you a way to extract the URL from a link; google to find out what it is. Remember how we turn a list into a dataframe.

At the end, you'll have three dataframes that you want to combine into a single dataframe. When we want to combine the rows of identical dataframes, we used `bind_rows()`. If you were combining columns instead of rows, there's a similar function. Find out what it is and use it to put all of the dataframes together into a single one.

When you're done, rename the columns so they make sense, then make sure the date column is an actual date.

Finally, tell me what questions you could ask of this data if you had all of his press releases. Be creative.

**I would ask of this data how often and what language calls aginst Trump vhollen has made through press releases.**

```{r URL}

vhollen_re_url <- "https://www.vanhollen.senate.gov/news/press-releases"

```

```{r Getting}

vhollen_raw_html <- vhollen_re_url |>
  read_html()

vhollen_dates <- vhollen_raw_html |>
  html_elements('.ArticleBlock__titleContainer .Heading--time') |>
  html_text() |>
  as_tibble() |>
  rename(date = value)

vhollen_dates

vhollen_titles <- vhollen_raw_html |>
  html_elements('.ArticleBlock__titleContainer h2') |>
  html_text() |>
  as_tibble() |>
  rename(title = value)

vhollen_titles

```

```{r Getting indiv urls}

vhollen_urls <- vhollen_raw_html |>
  html_elements('.ArticleBlock__titleContainer a') |>
  html_attr("href") |>
  as_tibble() |>
  rename(url = value)

vhollen_urls

```

```{r Combining}

vhollen_data <- bind_cols(vhollen_dates, vhollen_titles, vhollen_urls)

vhollen_data

```

```{r Cleaning}

cleaned_vhollen_data <- vhollen_data |>
  mutate(cleaned_date = mdy(date))

cleaned_vhollen_data

```

